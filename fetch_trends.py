from pytrends.request import TrendReq
import pandas as pd
from datetime import datetime
import time
import random
import os

# Ù†Ú¯Ø§Ø´Øª ÙØ§Ø±Ø³ÛŒ â†’ Ù¾ÛŒÙ†Ú¯Ù„ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
keyword_map = {
    'Ø®Ø±ÛŒØ¯ Ø¯Ù„Ø§Ø±': 'kharid_dollar',
    'ÙØ±ÙˆØ´ Ø¯Ù„Ø§Ø±': 'foroosh_dollar',
    'Ø¯Ù„Ø§Ø± ÙØ±Ø¯Ø§': 'dollar_farda',
    'Ù†Ø±Ø® Ø§Ø±Ø²': 'nerkh_arz',
    'Ø³Ú©Ù‡ Ø·Ù„Ø§': 'sekke_tala',
    'ØµØ±Ø§ÙÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ†': 'sarafi_online',
    'ØªÙˆØ±Ù…': 'tavvarom',
    'Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª': 'entekhabat',
    'Ø§Ø¹ØªØ±Ø§Ø¶Ø§Øª': 'eeteraaz',
    'ØªØ­Ø±ÛŒÙ…': 'tahrim',
    'Ø¨Ø±Ø¬Ø§Ù…': 'barjam',
    'Ø§Ù†ÙØ¬Ø§Ø±': 'enfejar',
    'ØªØ±ÙˆØ±': 'teror',
    'Ø­Ù…Ù„Ù‡': 'hamle',
    'Ø¬Ù†Ú¯': 'jang'
}

# Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ (ÙÙ‚Ø· ÙØ§Ø±Ø³ÛŒ)
keywords = list(keyword_map.keys())

# ØªÙ‚Ø³ÛŒÙ… Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ ÛµØªØ§ÛŒÛŒ
def chunk_keywords(lst, size=5):
    for i in range(0, len(lst), size):
        yield lst[i:i+size]

# Ø³Ø§Ø®Øª session Ù¾Ø§ÛŒØ¯Ø§Ø± Ø¨Ø§ Pytrends
pytrends = TrendReq(hl='fa', tz=330)

# ØªÙ†Ø¸ÛŒÙ… Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ
today_str = datetime.today().strftime('%Y-%m-%d')
output_folder = "data"
os.makedirs(output_folder, exist_ok=True)
output_path = os.path.join(output_folder, f"trends_{today_str}.csv")

# Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÙˆÙ‚Øª
all_data = []

for group in chunk_keywords(keywords, 5):
    print(f"ğŸ“¡ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ: {group}")
    try:
        pytrends.build_payload(group, timeframe='now 4-H')
        data = pytrends.interest_over_time()
        if not data.empty:
            data = data.drop(columns='isPartial')
            data.rename(columns=keyword_map, inplace=True)
            all_data.append(data)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ù‡Ù†Ú¯Ø§Ù… Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {group}: {e}")
    time.sleep(random.uniform(5, 10))  # ØªØ§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù†

# Ø§Ø¯ØºØ§Ù… Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
if all_data:
    result_df = pd.concat(all_data, axis=1)
    result_df = result_df.loc[:,~result_df.columns.duplicated()]  # Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
    result_long = result_df.reset_index().melt(id_vars=['date'], var_name='keyword', value_name='hits')
    result_long['date'] = result_long['date'].dt.strftime('%#m/%#d/%Y')
    result_long.to_csv(output_path)
    print(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯: {output_path}")
else:
    print("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
